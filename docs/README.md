
# Real-Time Cancer Detection with XAI and LLM Explanations

*Empowering patients and doctors with AI-driven cancer insights.*

---

## Overview

This project is a **real-time cancer detection system** featuring a PyQt6 GUI, leveraging deep learning, Explainable AI (XAI), and Large Language Models (LLMs). It processes MRI images to predict cancer types, generates XAI visualizations, and provides tailored explanations for patients and doctors/engineers.

- **Purpose**: Detect cancer in real-time, explain predictions visually, and communicate results clearly.
- **Dataset**: [Multi Cancer Dataset](https://www.kaggle.com/datasets/obulisainaren/multi-cancer) (a publicly available dataset with folder-per-class structure, containing MRI images for 8 cancer types: ALL, Brain Cancer, Breast Cancer, Cervical Cancer, Kidney Cancer, Lung and Colon Cancer, Lymphoma, and Oral Cancer).
- **Tech Stack**: Python, PyQt6, TensorFlow, Keras, OpenCV, LIME, Hugging Face LLM.
- **Date**: March 2025.

---

## Features

| **Feature**              | **Description**                                                                 |
|--------------------------|---------------------------------------------------------------------------------|
| **Cancer Prediction**    | Classifies cancer types (e.g., Brain, Breast, Lung) with confidence scores.     |
| **XAI Visualizations**   | Uses Grad-CAM, Saliency Map, and LIME to highlight critical image regions.      |
| **Dual Explanations**    | Patient-friendly summaries and technical insights for doctors/engineers.        |
| **Real-Time Input**      | Supports image uploads and webcam capture for instant analysis.                 |
| **Responsive GUI**       | PyQt6 interface with tabs, progress bars, themes, tooltips, and privacy notice. |
| **Testing & Training**   | Includes scripts to test the model and train from scratch with XAI.             |

---

## Installation

### Prerequisites
- Python 3.8+
- Git
- Webcam (optional, for real-time capture)

### Steps
1. **Clone the Repository**
   ```bash
   git clone https://github.com/fishe47/real-time-cancer-detection-xai.git
   cd real-time-cancer-detection-xai
   ```

2. **Set Up a Virtual Environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/macOS
   venv\Scripts\activate     # Windows
   ```

3. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Place the Pre-trained Model**
   - Download or place `cancer_classifier_xai.h5` in the `models/` directory.
   - Alternatively, run `scripts/train_model_with_xai.py` to generate it (requires dataset).

5. **Set Up Hugging Face API**
   - Replace `HUGGING_FACE_API_TOKEN` in `src/cancer_detection_gui.py` and `scripts/llm_explanation_generator.py` with your token from [Hugging Face](https://huggingface.co/settings/tokens).

6. **Prepare Dataset (Optional)**
   - Place a subset of the Multi Cancer Dataset in `data/Multi_Cancer/` (e.g., 1-2 images per class) if you want to run tests or training.

---

## Usage

### Run the GUI
```bash
python src/cancer_detection_gui.py
```
- **Patients Tab**: Upload an MRI image or capture from a webcam, then click "Process Image" for predictions and explanations.
- **Doctors/Engineers Tab**: View technical details, XAI insights, and performance metrics.
- **Features**: Toggle themes, check help, and monitor progress.

### Test the Model
```bash
python tests/test_with_h5.py
```
- Generates `outputs/xai_output.json` and `outputs/performance_metrics.json` using one image per class.
- Requires dataset in `data/Multi_Cancer/` and model in `models/`.

### Generate LLM Explanations
```bash
python scripts/llm_explanation_generator.py
```
- Processes `outputs/xai_output.json` (generated by `test_with_h5.py`) to produce layman-friendly explanations.
- Requires a Hugging Face API token.

### Train a New Model (Optional)
```bash
python scripts/train_model_with_xai.py
```
- Trains a VGG16-based model on a sampled dataset and saves it as `models/cancer_classifier_xai.h5`.
- Overwrites the existing model; use cautiously.
- Requires dataset in `data/Multi_Cancer/`.

---

## Screenshots

![xAI and LLM output in GUI](assets/screenshot.jpg) 

---

## Project Structure

```
real-time-cancer-detection-xai/
‚îú‚îÄ‚îÄ models/                  # Pre-trained models
‚îÇ   ‚îî‚îÄ‚îÄ cancer_classifier_xai.h5
‚îú‚îÄ‚îÄ src/                     # Source code
‚îÇ   ‚îî‚îÄ‚îÄ cancer_detection_gui.py  # Main GUI script
‚îú‚îÄ‚îÄ tests/                   # Unit tests or validation scripts
‚îÇ   ‚îî‚îÄ‚îÄ test_with_h5.py      # Test script for model validation
‚îú‚îÄ‚îÄ scripts/                 # Optional scripts
‚îÇ   ‚îú‚îÄ‚îÄ llm_explanation_generator.py  # LLM explanation generator
‚îÇ   ‚îî‚îÄ‚îÄ train_model_with_xai.py       # Model training script
‚îú‚îÄ‚îÄ outputs/                 # Generated outputs (optional examples)
‚îÇ   ‚îú‚îÄ‚îÄ real_time_xai_output.json
‚îÇ   ‚îú‚îÄ‚îÄ xai_output.json
‚îÇ   ‚îî‚îÄ‚îÄ performance_metrics.json
‚îú‚îÄ‚îÄ data/                    # Dataset (optional subset)
‚îÇ   ‚îî‚îÄ‚îÄ Multi_Cancer/        # Folder-per-class structure
‚îú‚îÄ‚îÄ docs/                    # Documentation
‚îÇ   ‚îî‚îÄ‚îÄ README.md            # This file
‚îú‚îÄ‚îÄ .gitignore               # Ignore files/folders
‚îú‚îÄ‚îÄ requirements.txt         # Dependencies
‚îî‚îÄ‚îÄ LICENSE                  # License file (e.g., MIT)
```

---

## How It Works

1. **Image Input**: Upload an MRI or capture from a webcam via the GUI.
2. **Preprocessing**: Resizes to 224x224 and normalizes pixel values.
3. **Prediction**: Uses a pre-trained Keras model to classify cancer type.
4. **XAI**: Generates Grad-CAM, Saliency Map, and LIME visuals to explain predictions.
5. **LLM Explanations**:
   - Patients: Simple, hopeful language with survival facts.
   - Doctors/Engineers: Technical details with XAI insights.
6. **Display**: Shows results in the PyQt6 GUI.

---

## Explainable AI (XAI)

XAI enhances the transparency of AI models by providing insights into their decision-making process. In this project:
- **Grad-CAM**: Highlights the regions of an image most influential to the model‚Äôs prediction, using gradient information.
- **Saliency Map**: Visualizes pixel importance based on gradients, emphasizing edges or features.
- **LIME**: Approximates the model locally with interpretable rules, overlaying boundaries on the image.
These techniques help users (e.g., doctors) trust and understand the AI‚Äôs cancer predictions.

---

## Models Used

- **Pre-trained Model (`cancer_classifier_xai.h5`)**: A Keras model trained on the Multi Cancer Dataset, used for real-time predictions in the GUI and testing. It‚Äôs either provided pre-trained or generated by `train_model_with_xai.py`.
- **Training Model (VGG16-based)**: Used in `train_model_with_xai.py` to create `cancer_classifier_xai.h5` from scratch.

---

## Deep Learning Architecture: VGG16

The project employs **VGG16**, a convolutional neural network (CNN) architecture developed by the Visual Geometry Group at Oxford. Key details:
- **Structure**: 
  - 16 layers, including 13 convolutional layers (with 3x3 filters) and 3 fully connected layers.
  - Uses small receptive fields (3x3) with increasing depth (64 to 512 filters).
  - Max pooling layers reduce spatial dimensions.
  - Final layers include a softmax for 8-class classification.
- **Pre-training**: Initialized with ImageNet weights, fine-tuned on the Multi Cancer Dataset.
- **Modifications**: Top layers replaced with a GlobalAveragePooling2D and a Dense layer (128 units, ReLU), followed by a 8-unit softmax layer for cancer classification.
- **Training**: Uses data augmentation (rotation, shifts, flips) and the Adam optimizer with sparse categorical cross-entropy loss.

This architecture balances depth and performance, making it suitable for medical image classification.

---

## Configuration

Update these in the respective scripts:
- **`src/cancer_detection_gui.py`**:
  - `MODEL_PATH`: Path to your `.h5` model (default: `models/cancer_classifier_xai.h5`).
  - `OUTPUT_FILE`: Results storage (default: `outputs/real_time_xai_output.json`).
  - `PERFORMANCE_METRICS_FILE`: Metrics storage (default: `outputs/performance_metrics.json`).
  - `HUGGING_FACE_API_TOKEN`: Your API key.
- **`tests/test_with_h5.py`**:
  - `DATA_DIR`: Dataset path (default: `data/Multi_Cancer`).
  - `MODEL_PATH`: Model path (default: `models/cancer_classifier_xai.h5`).
- **`scripts/llm_explanation_generator.py`**:
  - `XAI_OUTPUT_FILE`: Input JSON path (default: `outputs/xai_output.json`).
  - `HUGGING_FACE_API_TOKEN`: Your API key.
- **`scripts/train_model_with_xai.py`**:
  - `DATA_DIR`: Dataset path (default: `data/Multi_Cancer`).
  - `SAMPLE_SIZE_PER_CLASS`: Number of images per class (default: 50).

---

## Contributing

1. Fork the repo.
2. Create a branch: `git checkout -b feature/your-feature`.
3. Commit changes: `git commit -m "Add your feature"`.
4. Push: `git push origin feature/your-feature`.
5. Open a Pull Request.

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## Acknowledgments

- **Dataset**: Multi Cancer Dataset (https://www.kaggle.com/datasets/obulisainaren/multi-cancer) .
- **Tools**: TensorFlow, Keras, PyQt6, LIME, Hugging Face.
- **Community**: Thanks to all open-source contributors!

---

## Contact

üìß Email: srirajsarkar2000@gmail.com
üí° Issues: [GitHub Issues](https://github.com/fishe47/real-time-cancer-detection-xai/issues)

---

*Built with ‚ù§Ô∏è by Sriraj in March 2025. Let‚Äôs fight cancer together! ‚ú®*
```

---